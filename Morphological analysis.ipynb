{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puA-lluiMQ_z"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import (\n",
        "    PunktSentenceTokenizer, TreebankWordTokenizer, word_tokenize, RegexpTokenizer\n",
        ")\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, SnowballStemmer, RegexpStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and download necessary packages\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBxb5SmmPjT5",
        "outputId": "677cd14f-c860-4e10-dcee-57d7ce162eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paragraph for analysis\n",
        "paragraph = (\n",
        "    \"Finance refers to monetary resources and to the study and discipline of money, currency, assets and liabilities. \"\n",
        "    \"As a subject of study, it is related to but distinct from economics, which is the study of the production, distribution, and consumption of goods and services.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "FEpxdoe0Prce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Punkt Sentence Tokenizer\n",
        "punkt_tokenizer = PunktSentenceTokenizer()\n",
        "sentences = punkt_tokenizer.tokenize(paragraph)\n",
        "print(\"\\nTokenization (Punkt Sentence Tokenizer):\")\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-vfm4v1P5-V",
        "outputId": "d8904774-bc90-4b8a-958c-b9c7aa36c1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenization (Punkt Sentence Tokenizer):\n",
            "['Finance refers to monetary resources and to the study and discipline of money, currency, assets and liabilities.', 'As a subject of study, it is related to but distinct from economics, which is the study of the production, distribution, and consumption of goods and services.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treebank Word Tokenizer\n",
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "treebank_tokens = treebank_tokenizer.tokenize(paragraph)\n",
        "print(\"\\nTokenization (Treebank Word Tokenizer):\")\n",
        "print(treebank_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqFzBPETP-be",
        "outputId": "b34fdddc-f890-4dae-d321-cc331a33f86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenization (Treebank Word Tokenizer):\n",
            "['Finance', 'refers', 'to', 'monetary', 'resources', 'and', 'to', 'the', 'study', 'and', 'discipline', 'of', 'money', ',', 'currency', ',', 'assets', 'and', 'liabilities.', 'As', 'a', 'subject', 'of', 'study', ',', 'it', 'is', 'related', 'to', 'but', 'distinct', 'from', 'economics', ',', 'which', 'is', 'the', 'study', 'of', 'the', 'production', ',', 'distribution', ',', 'and', 'consumption', 'of', 'goods', 'and', 'services', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download the 'punkt_tab' dataset\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Now, you can use word_tokenize as before:\n",
        "word_tokens = word_tokenize(paragraph)\n",
        "print(\"\\nTokenization (Word Tokenizer):\")\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5XFE0X9QdGV",
        "outputId": "d8120336-7dbd-473a-fb8a-e5de1f161db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenization (Word Tokenizer):\n",
            "['Finance', 'refers', 'to', 'monetary', 'resources', 'and', 'to', 'the', 'study', 'and', 'discipline', 'of', 'money', ',', 'currency', ',', 'assets', 'and', 'liabilities', '.', 'As', 'a', 'subject', 'of', 'study', ',', 'it', 'is', 'related', 'to', 'but', 'distinct', 'from', 'economics', ',', 'which', 'is', 'the', 'study', 'of', 'the', 'production', ',', 'distribution', ',', 'and', 'consumption', 'of', 'goods', 'and', 'services', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular Expression Tokenizer\n",
        "regexp_tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "regexp_tokens = regexp_tokenizer.tokenize(paragraph)\n",
        "print(\"\\nTokenization (RegExp Tokenizer):\")\n",
        "print(regexp_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-LvYLr2Qjwc",
        "outputId": "a1ec94ea-0e9d-44bb-9e35-8f6eddd86c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenization (RegExp Tokenizer):\n",
            "['Finance', 'refers', 'to', 'monetary', 'resources', 'and', 'to', 'the', 'study', 'and', 'discipline', 'of', 'money', 'currency', 'assets', 'and', 'liabilities', 'As', 'a', 'subject', 'of', 'study', 'it', 'is', 'related', 'to', 'but', 'distinct', 'from', 'economics', 'which', 'is', 'the', 'study', 'of', 'the', 'production', 'distribution', 'and', 'consumption', 'of', 'goods', 'and', 'services']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sentence Segmentation\n",
        "print(\"\\nSentence Segmentation:\")\n",
        "for idx, sentence in enumerate(sentences, start=1):\n",
        "    print(f\"Sentence {idx}: {sentence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy1O2gJ5QoZU",
        "outputId": "c67ec272-5faf-472e-801a-f896a4acc2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence Segmentation:\n",
            "Sentence 1: Finance refers to monetary resources and to the study and discipline of money, currency, assets and liabilities.\n",
            "Sentence 2: As a subject of study, it is related to but distinct from economics, which is the study of the production, distribution, and consumption of goods and services.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization using WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in word_tokens]\n",
        "print(\"\\nLemmatization (WordNet Lemmatizer):\")\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0N9SVAzQrur",
        "outputId": "8164b2ae-3f82-4b53-9b77-96a7104e4342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lemmatization (WordNet Lemmatizer):\n",
            "['finance', 'refers', 'to', 'monetary', 'resource', 'and', 'to', 'the', 'study', 'and', 'discipline', 'of', 'money', ',', 'currency', ',', 'asset', 'and', 'liability', '.', 'a', 'a', 'subject', 'of', 'study', ',', 'it', 'is', 'related', 'to', 'but', 'distinct', 'from', 'economics', ',', 'which', 'is', 'the', 'study', 'of', 'the', 'production', ',', 'distribution', ',', 'and', 'consumption', 'of', 'good', 'and', 'service', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming using Porter Stemmer\n",
        "porter_stemmer = PorterStemmer()\n",
        "porter_stemmed_words = [porter_stemmer.stem(word) for word in word_tokens]\n",
        "print(\"\\nStemming (Porter Stemmer):\")\n",
        "print(porter_stemmed_words)\n",
        "\n",
        "# Stemming using Snowball Stemmer\n",
        "snowball_stemmer = SnowballStemmer(\"english\")\n",
        "snowball_stemmed_words = [snowball_stemmer.stem(word) for word in word_tokens]\n",
        "print(\"\\nStemming (Snowball Stemmer):\")\n",
        "print(snowball_stemmed_words)\n",
        "\n",
        "# Stemming using RegExp Stemmer\n",
        "regexp_stemmer = RegexpStemmer(\"ing$|ed$|ly$\", min=4)\n",
        "regexp_stemmed_words = [regexp_stemmer.stem(word) for word in word_tokens]\n",
        "print(\"\\nStemming (RegExp Stemmer):\")\n",
        "print(regexp_stemmed_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXECgH9XQwVz",
        "outputId": "6462af45-33d5-418a-c7b1-5b3b9925da3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stemming (Porter Stemmer):\n",
            "['financ', 'refer', 'to', 'monetari', 'resourc', 'and', 'to', 'the', 'studi', 'and', 'disciplin', 'of', 'money', ',', 'currenc', ',', 'asset', 'and', 'liabil', '.', 'as', 'a', 'subject', 'of', 'studi', ',', 'it', 'is', 'relat', 'to', 'but', 'distinct', 'from', 'econom', ',', 'which', 'is', 'the', 'studi', 'of', 'the', 'product', ',', 'distribut', ',', 'and', 'consumpt', 'of', 'good', 'and', 'servic', '.']\n",
            "\n",
            "Stemming (Snowball Stemmer):\n",
            "['financ', 'refer', 'to', 'monetari', 'resourc', 'and', 'to', 'the', 'studi', 'and', 'disciplin', 'of', 'money', ',', 'currenc', ',', 'asset', 'and', 'liabil', '.', 'as', 'a', 'subject', 'of', 'studi', ',', 'it', 'is', 'relat', 'to', 'but', 'distinct', 'from', 'econom', ',', 'which', 'is', 'the', 'studi', 'of', 'the', 'product', ',', 'distribut', ',', 'and', 'consumpt', 'of', 'good', 'and', 'servic', '.']\n",
            "\n",
            "Stemming (RegExp Stemmer):\n",
            "['Finance', 'refers', 'to', 'monetary', 'resources', 'and', 'to', 'the', 'study', 'and', 'discipline', 'of', 'money', ',', 'currency', ',', 'assets', 'and', 'liabilities', '.', 'As', 'a', 'subject', 'of', 'study', ',', 'it', 'is', 'relat', 'to', 'but', 'distinct', 'from', 'economics', ',', 'which', 'is', 'the', 'study', 'of', 'the', 'production', ',', 'distribution', ',', 'and', 'consumption', 'of', 'goods', 'and', 'services', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopword Removal\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_words = [word for word in lemmatized_words if word not in stop_words and word not in string.punctuation]\n",
        "print(\"\\nStopword Removal Result:\")\n",
        "print(filtered_words)\n",
        "\n",
        "# Porter Stemmer Example\n",
        "print(\"\\nPorter Stemmer Examples:\")\n",
        "words = [\"play\", \"playing\", \"played\", \"plays\"]\n",
        "for word in words:\n",
        "    print(f\"Original: {word} -> Stemmed: {porter_stemmer.stem(word)}\")\n",
        "\n",
        "# Snowball Stemmer Example\n",
        "print(\"\\nSnowball Stemmer Examples:\")\n",
        "words = [\"Excellent\", \"service\"]\n",
        "for word in words:\n",
        "    print(f\"Original: {word} -> Stemmed: {snowball_stemmer.stem(word)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ02ZR1eQ12r",
        "outputId": "7e288f50-5d39-4383-f787-6309a5cf81fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stopword Removal Result:\n",
            "['finance', 'refers', 'monetary', 'resource', 'study', 'discipline', 'money', 'currency', 'asset', 'liability', 'subject', 'study', 'related', 'distinct', 'economics', 'study', 'production', 'distribution', 'consumption', 'good', 'service']\n",
            "\n",
            "Porter Stemmer Examples:\n",
            "Original: play -> Stemmed: play\n",
            "Original: playing -> Stemmed: play\n",
            "Original: played -> Stemmed: play\n",
            "Original: plays -> Stemmed: play\n",
            "\n",
            "Snowball Stemmer Examples:\n",
            "Original: Excellent -> Stemmed: excel\n",
            "Original: service -> Stemmed: servic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RegExp Tokenizer Example\n",
        "print(\"\\nRegExp Tokenizer Examples:\")\n",
        "regexp_tokenizer_advanced = RegexpTokenizer(\"[\\\\w']+\")\n",
        "text_example = \"Let's see how it's working.\"\n",
        "print(regexp_tokenizer_advanced.tokenize(text_example))\n",
        "\n",
        "# Treebank Word Tokenizer Example\n",
        "print(\"\\nTreebank Word Tokenizer Example:\")\n",
        "print(treebank_tokenizer.tokenize(\"Why blood? Same blood.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUhVg9OMQ6wT",
        "outputId": "abc4b804-f933-4734-99fa-bde7490ac4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RegExp Tokenizer Examples:\n",
            "[\"Let's\", 'see', 'how', \"it's\", 'working']\n",
            "\n",
            "Treebank Word Tokenizer Example:\n",
            "['Why', 'blood', '?', 'Same', 'blood', '.']\n"
          ]
        }
      ]
    }
  ]
}